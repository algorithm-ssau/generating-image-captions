{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "studied-imaging",
   "metadata": {},
   "source": [
    "# Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-israel",
   "metadata": {},
   "source": [
    "### fit_generator\n",
    "\n",
    "Поставляет модель Keras Sequential на основе данных, сгенерированных пакетно по пакетам генератором Python (или экземпляром Sequence).\n",
    "\n",
    "Генератор работает параллельно с моделью, для большей эффективности. Например, это позволяет выполнять увеличение данных на изображениях на CPU в реальном времени параллельно с обучением модели на GPU.\n",
    "\n",
    "Использование ```keras.utils.Sequence``` гарантирует упорядочение и однократное использование каждого входа в эпоху при использовании ```use_multiprocessing=True```.\n",
    "\n",
    "```generator```: Генератор или экземпляр объекта ```keras.utils.Sequence```, чтобы избежать дублирования данных при использовании многопроцессорной обработки. \n",
    "\n",
    "Выходной сигнал генератора должен быть либо кортеж (inputs, targets), либо кортеж (inputs, targets, sample_weights).\n",
    "Этот кортеж (один выход генератора) составляет одну партию. Поэтому все массивы в этом кортеже должны иметь одинаковую длину (равную размеру этой партии). Различные партии могут иметь разные размеры. Например, последняя партия эпохи обычно меньше остальных, если размер набора данных не делится на размер партии. Предполагается, что генератор будет перебирать данные бесконечно. Эпоха заканчивается, когда модель видит партии ```steps_per_epoch```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-consequence",
   "metadata": {},
   "source": [
    "### ImageGenerator(Sequence)\n",
    "\n",
    "Обучение с ```fit_generator```:\n",
    "1. Получение данных партиями от генератора;\n",
    "2. Обновление весов модели на основе полученной партии;\n",
    "3. Повторять.\n",
    "________\n",
    "```Sequence``` are a safer way to do multiprocessing. This structure guarantees that the network will only train once on each sample per epoch which is not the case with generators.\n",
    "________\n",
    "```__getitem__(self, idx)``` gets batch at position index.\n",
    "* ```idx``` – индекс партии.\n",
    "________\n",
    "```__iter__``` create a generator that iterate over the ```Sequence```.\n",
    "* ```len(self)```                 – возвращает кол-во партий.\n",
    "* ```for i in range(len(self))``` – для каждой партии.\n",
    "________\n",
    "```__len__``` gets the number of batch in the ```Sequence```.\n",
    "________\n",
    "shape=(224,224,3)\n",
    "* 244 – ширина изображения;\n",
    "* 244 – высота изображения;\n",
    "* 3 – цвет в RGB.\n",
    "________\n",
    "Note: each Keras Application expects a specific kind of input preprocessing. \n",
    "For ```DenseNet```, call ```tf.keras.applications.densenet.preprocess_input``` on your inputs before passing them to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-recycling",
   "metadata": {},
   "source": [
    "### ModelCheckpoint\n",
    "\n",
    "Callback to save the Keras model or model weights at some frequency.\n",
    "\n",
    "ModelCheckpoint callback is used in conjunction with training using model.fit() to save a model or weights (in a checkpoint file) at some interval, so the model or weights can be loaded later to continue the training from the state saved.\n",
    "\n",
    "```monitor``` – The metric name to monitor.\n",
    "Prefix the name with ```val_``` to monitor validation metrics.\n",
    "\n",
    "```verbose=0``` will show you nothing (silent).\n",
    "```verbose=1``` will show you an animated progress bar.\n",
    "\n",
    "```save_best_only```: if ```save_best_only=True```, it only saves when the model is considered the \"best\" and the latest best model according to the quantity monitored will not be overwritten. \n",
    "If filepath doesn't contain formatting options like {epoch} then filepath will be overwritten by each new better model.\n",
    "\n",
    "```mode```: one of {'auto', 'min', 'max'}. If ```save_best_only=True```, the decision to overwrite the current save file is made based on either the maximization or the minimization of the monitored quantity. \n",
    "For ```val_acc```, this should be ```max```, for ```val_loss``` this should be ```min```, etc. In ```auto``` mode, the direction is automatically inferred from the name of the monitored quantity.\n",
    "\n",
    "https://keras.io/api/callbacks/model_checkpoint/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-finnish",
   "metadata": {},
   "source": [
    "### ReduceLROnPlateau\n",
    "\n",
    "Reduce learning rate when a metric has stopped improving.\n",
    "\n",
    "Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.\n",
    " \n",
    "```monitor```: quantity to be monitored.\n",
    "\n",
    "```factor```: factor by which the learning rate will be reduced. ```new_lr = lr * factor```.\n",
    "\n",
    "```patience```: number of epochs with no improvement after which learning rate will be reduced.\n",
    "\n",
    "```verbose```: int. 0: quiet, 1: update messages.\n",
    "\n",
    "```mode```: one of {'auto', 'min', 'max'}. \n",
    "In 'min' mode, the learning rate will be reduced when the quantity monitored has stopped decreasing; \n",
    "in 'max' mode it will be reduced when the quantity monitored has stopped increasing; \n",
    "in 'auto' mode, the direction is automatically inferred from the name of the monitored quantity.\n",
    "\n",
    "```min_delta```: threshold for measuring the new optimum, to only focus on significant changes.\n",
    "\n",
    "```cooldown```: number of epochs to wait before resuming normal operation after lr has been reduced.\n",
    "\n",
    "```min_lr```: lower bound on the learning rate.\n",
    " \n",
    "https://keras.io/api/callbacks/reduce_lr_on_plateau/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-proceeding",
   "metadata": {},
   "source": [
    "### EarlyStopping\n",
    "\n",
    "Stop training when a monitored metric has stopped improving.\n",
    "\n",
    "Assuming the goal of a training is to minimize the loss. With this, the metric to be monitored would be ```loss```, and mode would be ```min```. \n",
    "\n",
    "A ```model.fit()``` training loop will check at end of every epoch whether the loss is no longer decreasing, considering the ```min_delta``` and ```patience``` if applicable. Once it's found no longer decreasing, model.stop_training is marked True and the training terminates.\n",
    "\n",
    "```patience```: Number of epochs with no improvement after which training will be stopped.\n",
    "\n",
    "https://keras.io/api/callbacks/early_stopping/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
