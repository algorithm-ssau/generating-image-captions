{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.merge import add\n",
    "\n",
    "curr_folder = \"D:/YandexDisk/datasets/\"\n",
    "end_dir = \"D:/datasets/flickr-images-12k\"\n",
    "\n",
    "path_features = curr_folder + \"ru-12k-features.pkl\"\n",
    "path_vocab = curr_folder + \"ru-12k-vocab.pkl\"\n",
    "path_sentences = curr_folder + \"ru-12k-sentences-train.pkl\"\n",
    "path_tokenizer = curr_folder + \"ru-12k-tokenizer-train.pkl\"\n",
    "\n",
    "path_train_dict = curr_folder + \"captions-ru-12k-train.pkl\"\n",
    "path_val_dict = curr_folder + \"captions-ru-12k-val.pkl\"\n",
    "\n",
    "def image_names_set(data):\n",
    "    vals = set()\n",
    "\n",
    "    for idx in data.index:\n",
    "        vals.add(data.iat[idx, 0][:-4])\n",
    "\n",
    "    return vals\n",
    "\n",
    "def load_image_features(filename, data):\n",
    "    all_features = pickle.load(open(filename, 'rb'))\n",
    "    features = {k: all_features[k] for k in data}\n",
    "\n",
    "    return features\n",
    "\n",
    "def to_lines(data):\n",
    "    all_vals = list()\n",
    "    for key in data.keys():\n",
    "        [all_vals.append(d) for d in data[key]]\n",
    "\n",
    "    return all_vals\n",
    "\n",
    "def create_tokenizer(data):\n",
    "    lines = to_lines(data)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "def find_max_words(data):\n",
    "    lines = to_lines(data)\n",
    "    return max(len(l.split()) for l in lines)\n",
    "\n",
    "def create_sequences(tokenizer, max_words, captions_list, image_name):\n",
    "    X_image, X_text, y_word = list(), list(), list()\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    for caption in captions_list:\n",
    "        seq = tokenizer.texts_to_sequences([caption])[0]\n",
    "\n",
    "        for i in range(1, len(seq)):\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "            in_seq = pad_sequences([in_seq], maxlen=max_words)[0]\n",
    "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\n",
    "            X_image.append(image_name)\n",
    "            X_text.append(in_seq)\n",
    "            y_word.append(out_seq)\n",
    "\n",
    "    return X_image, X_text, y_word\n",
    "\n",
    "def data_generator(tokenizer, max_words, data, images, batch_size, random_seed):\n",
    "    count = 0\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    img_names = list(data.keys())\n",
    "    assert batch_size <= len(img_names), 'batch size must be less than or equal to {}'.format(len(img_names))\n",
    "\n",
    "    while True:\n",
    "        input_img_batch, input_seq_batch, output_word_batch = list(), list(), list()\n",
    "\n",
    "        if count >= len(img_names):\n",
    "            count = 0\n",
    "        start_i = count\n",
    "        end_i = min(len(img_names), count + batch_size)\n",
    "\n",
    "        for i in range(start_i, end_i):\n",
    "            curr_img = img_names[i]\n",
    "            image = images[curr_img][0]\n",
    "            captions_list = data[curr_img]\n",
    "            random.shuffle(captions_list)\n",
    "\n",
    "            input_img, input_seq, output_word = create_sequences(tokenizer, max_words, captions_list, image)\n",
    "\n",
    "            for j in range(len(input_img)):\n",
    "                input_img_batch.append(input_img[j])\n",
    "                input_seq_batch.append(input_seq[j])\n",
    "                output_word_batch.append(output_word[j])\n",
    "\n",
    "        count = count + batch_size\n",
    "        yield [np.array(input_img_batch), np.array(input_seq_batch)], np.array(output_word_batch)\n",
    "\n",
    "with open (path_train_dict, 'rb') as f:\n",
    "    train_dict = pickle.load(f)\n",
    "train_features = load_image_features(path_features, train_dict)\n",
    "print('кол-во подписей .............. %d' % len(train_dict))\n",
    "\n",
    "with open (path_sentences, 'rb') as f:\n",
    "    sentences = pickle.load(f)\n",
    "tokenizer = create_tokenizer(train_dict)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('размер словаря ............... %d' % vocab_size)\n",
    "\n",
    "max_words = find_max_words(train_dict)\n",
    "print('длина предложения в словах ... %d' % max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1713692510423848579\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3129068339\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4954210445840460104\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, max_words):\n",
    "    inputs1 = Input(shape=(4096,))\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "    inputs2 = Input(shape=(max_words,))\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(256)(se2)\n",
    "\n",
    "    de1 = add([fe2, se3])\n",
    "    de2 = Dense(256, activation='relu')(de1)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(de2)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 16\n",
    "\n",
    "model = build_model(vocab_size, max_words)\n",
    "steps = len(train_dict)/batch_size\n",
    "if len(train_dict) % batch_size != 0:\n",
    "    steps = steps + 1\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(epochs):\n",
    "    generator = data_generator(tokenizer, max_words, train_dict, train_features, batch_size, 42)\n",
    "    model.fit(generator,\n",
    "              epochs=1, steps_per_epoch=steps,\n",
    "              verbose=1)\n",
    "    model.save('model_' + str(i) + '.h5')\n",
    "time_difference = time.time() - start_time\n",
    "\n",
    "minutes = time_difference/60\n",
    "print('время обучения в минутах ..... %d' % minutes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open (path_val_dict, 'rb') as f:\n",
    "    val_dict = pickle.load(f)\n",
    "val_features = load_image_features(path_features, val_dict)\n",
    "print('кол-во подписей .............. %d' % len(val_dict))\n",
    "\n",
    "val_tokenizer = create_tokenizer(val_dict)\n",
    "val_vocab_size = len(val_tokenizer.word_index) + 1\n",
    "print('размер словаря ............... %d' % val_vocab_size)\n",
    "\n",
    "val_max_words = find_max_words(val_dict)\n",
    "print('длина предложения в словах ... %d' % val_max_words)\n",
    "\n",
    "def map_int_to_word(integer, tokenizer):\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        if idx == integer:\n",
    "            return word\n",
    "\n",
    "    return None\n",
    "\n",
    "def generate_caption(model, tokenizer, image, max_words):\n",
    "    in_text = 'startseq'\n",
    "\n",
    "    for i in range(max_words):\n",
    "        seq = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        seq = pad_sequences([seq], maxlen=max_words)\n",
    "\n",
    "        y_hat = model.predict([image,seq], verbose=0)\n",
    "        y_hat = np.argmax(y_hat)\n",
    "\n",
    "        word = map_int_to_word(y_hat, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "\n",
    "        in_text += ' ' + word\n",
    "\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "\n",
    "    return in_text\n",
    "\n",
    "def evaluate_model(model, captions, images, tokenizer, max_words):\n",
    "    actual, predicted = list(), list()\n",
    "\n",
    "    for key, captions_list in captions.items():\n",
    "        references = [c.split() for c in captions_list]\n",
    "        y_hat = generate_caption(model, tokenizer, images[key], max_words)\n",
    "\n",
    "        actual.append(references)\n",
    "        predicted.append(y_hat.split())\n",
    "\n",
    "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.361409\n",
      "BLEU-2: 0.193161\n",
      "BLEU-3: 0.137490\n",
      "BLEU-4: 0.055897\n"
     ]
    }
   ],
   "source": [
    "path_model = 'D:/models/model-0.h5'\n",
    "model = load_model(path_model)\n",
    "evaluate_model(model, val_dict, val_features, tokenizer, max_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}