{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from numpy import argmax\n",
    "\n",
    "from keras.models import Model\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from keras_preprocessing.image import load_img, img_to_array\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import preprocess_input as preprocess_input_i\n",
    "from keras.applications.vgg16 import preprocess_input as preprocess_input_v\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "curr_folder = \"D:/YandexDisk/datasets/\"\n",
    "path_tokenizer = curr_folder + \"ru-12k-tokenizer-train.pkl\"\n",
    "tokenizer = load(open(path_tokenizer, 'rb'))\n",
    "max_words = 22\n",
    "\n",
    "vgg16_extractor = VGG16()\n",
    "vgg16_extractor = Model(inputs=vgg16_extractor.inputs, outputs=vgg16_extractor.layers[-2].output)\n",
    "vgg16_target_size = 224\n",
    "\n",
    "inception_extractor = InceptionV3(weights=\"imagenet\")\n",
    "inception_extractor = Model(inputs=inception_extractor.inputs, outputs=inception_extractor.layers[-2].output)\n",
    "inception_target_size = 299\n",
    "\n",
    "v0 = \"D:/models/vgg16/model-0.h5\"\n",
    "v1 = \"D:/models/vgg16/model-1.h5\"\n",
    "v2 = \"D:/models/vgg16/model-2.h5\"\n",
    "v3 = \"D:/models/vgg16/model-3.h5\"\n",
    "v4 = \"D:/models/vgg16/model-4.h5\"\n",
    "v5 = \"D:/models/vgg16/model-5.h5\"\n",
    "v6 = \"D:/models/vgg16/model-6.h5\"\n",
    "v7 = \"D:/models/vgg16/model-7.h5\"\n",
    "v8 = \"D:/models/vgg16/model-8.h5\"\n",
    "v9 = \"D:/models/vgg16/model-9.h5\"\n",
    "v10 = \"D:/models/vgg16/model-10.h5\"\n",
    "v11 = \"D:/models/vgg16/model-11.h5\"\n",
    "v12 = \"D:/models/vgg16/model-12.h5\"\n",
    "v13 = \"D:/models/vgg16//model-13.h5\"\n",
    "v14 = \"D:/models/vgg16/model-14.h5\"\n",
    "v15 = \"D:/models/vgg16/model-15.h5\"\n",
    "v16 = \"D:/models/vgg16/model-16.h5\"\n",
    "v17 = \"D:/models/vgg16/model-17.h5\"\n",
    "v18 = \"D:/models/vgg16/model-18.h5\"\n",
    "v19 = \"D:/models/vgg16/model-19.h5\"\n",
    "\n",
    "i0 = \"D:/models/inception/model-0.h5\"\n",
    "i1 = \"D:/models/inception/model-1.h5\"\n",
    "i2 = \"D:/models/inception/model-2.h5\"\n",
    "i3 = \"D:/models/inception/model-3.h5\"\n",
    "i4 = \"D:/models/inception/model-4.h5\"\n",
    "i5 = \"D:/models/inception/model-5.h5\"\n",
    "i6 = \"D:/models/inception/model-6.h5\"\n",
    "i7 = \"D:/models/inception/model-7.h5\"\n",
    "i8 = \"D:/models/inception/model-8.h5\"\n",
    "i9 = \"D:/models/inception/model-9.h5\"\n",
    "i10 = \"D:/models/inception/model-10.h5\"\n",
    "i11 = \"D:/models/inception/model-11.h5\"\n",
    "i12 = \"D:/models/inception/model-12.h5\"\n",
    "i13 = \"D:/models/inception/model-13.h5\"\n",
    "i14 = \"D:/models/inception/model-14.h5\"\n",
    "i15 = \"D:/models/inception/model-15.h5\"\n",
    "i16 = \"D:/models/inception/model-16.h5\"\n",
    "i17 = \"D:/models/inception/model-17.h5\"\n",
    "i18 = \"D:/models/inception/model-18.h5\"\n",
    "i19 = \"D:/models/inception/model-19.h5\"\n",
    "\n",
    "v_models = [v0, v1, v2, v3, v4, v5, v6, v7, v8, v9,\n",
    "            v10, v11, v12, v13, v14, v15, v16, v17, v18, v19]\n",
    "\n",
    "i_models = [i0, i1, i2, i3, i4, i5, i6, i7, i8, i9,\n",
    "            i10, i11, i12, i13, i14, i15, i16, i17, i18, i19]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def map_int_to_word(integer, tokenizer):\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        if idx == integer:\n",
    "            return word\n",
    "\n",
    "    return None\n",
    "\n",
    "def generate_caption(model, tokenizer, max_words, image):\n",
    "    in_text = 'startseq'\n",
    "\n",
    "    for i in range(max_words):\n",
    "        seq = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        seq = pad_sequences([seq], maxlen=max_words)\n",
    "\n",
    "        y_hat = model.predict([image,seq], verbose=0)\n",
    "        y_hat = argmax(y_hat)\n",
    "\n",
    "        word = map_int_to_word(y_hat, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "\n",
    "        in_text += ' ' + word\n",
    "\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "\n",
    "    return in_text\n",
    "\n",
    "def print_image(path_image):\n",
    "    image = mpimg.imread(path_image)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def extract_features(path_image, extractor, target_size, model_type):\n",
    "    image = load_img(path_image, target_size=(target_size, target_size))\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    if model_type == \"vgg16\":\n",
    "        image = preprocess_input_v(image)\n",
    "    elif model_type == \"inception\":\n",
    "        image = preprocess_input_i(image)\n",
    "\n",
    "    feature = extractor.predict(image, verbose=0)\n",
    "\n",
    "    return feature\n",
    "\n",
    "def generate_and_print_captions(path_image, extractor, target_size, models_paths, model_type):\n",
    "    image_features = extract_features(path_image, extractor, target_size, model_type)\n",
    "\n",
    "    for i, path in enumerate(models_paths):\n",
    "        model = load_model(path)\n",
    "        caption = generate_caption(model, tokenizer, max_words, image_features)\n",
    "        print(str(i) + ' ' + caption)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}