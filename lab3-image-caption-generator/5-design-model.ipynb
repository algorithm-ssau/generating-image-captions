{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import array\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "images_folder = 'D:/datasets/flickr-30k-images'\n",
    "\n",
    "curr_folder = \"D:/YandexDisk/datasets/\"\n",
    "path_train = curr_folder + \"captions-ru-train.csv\"\n",
    "path_test = curr_folder + \"captions-ru-test.csv\"\n",
    "\n",
    "path_features = curr_folder + \"features.pkl\"\n",
    "path_sentences = curr_folder + \"sentences-train.pkl\"\n",
    "\n",
    "path_model = curr_folder + \"model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка данных\n",
    "\n",
    "Мы собираемся обучить данные по всем фотографиям и подписям в обучающем наборе данных. Во время обучения мы будем отслеживать производительность модели в наборе данных разработки и использовать эту производительность, чтобы решить, когда сохранять модели в файл.\n",
    "\n",
    "Модель, которую мы разработаем, будет генерировать подпись к фотографии, и подпись будет генерироваться по одному слову за раз.\n",
    "\n",
    "Последовательность ранее сгенерированных слов будет предоставлена в качестве входных данных. Поэтому нам понадобится \"первое слово\", чтобы начать процесс генерации, и \"последнее слово\", чтобы сигнализировать об окончании подписи. Для этой цели мы будем использовать строки \"startseq\" и \"endseq\". Эти маркеры добавляются к загруженным описаниям по мере их загрузки. Важно сделать это сейчас, прежде чем мы закодируем текст, чтобы токены также были закодированы правильно."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Закодировать знаки в числа\n",
    "\n",
    "Текст описания необходимо будет закодировать в числа, прежде чем его можно будет представить модели в качестве входных данных или сравнить с предсказаниями модели.\n",
    "\n",
    "Первым шагом в кодировании данных является создание согласованного сопоставления слов с уникальными целочисленными значениями. Keras предоставляет класс Tokenizer, который может изучить это сопоставление из загруженных данных описания.\n",
    "\n",
    "Каждое описание будет разделено на слова. Модель будет предоставлена одним словом и фотографией и сгенерирует следующее слово. Затем первые два слова описания будут предоставлены модели в качестве входных данных вместе с изображением для создания следующего слова. Именно так будет обучаться модель."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Создание последовательности\n",
    "\n",
    "Приведенная ниже функция с именем create_sequences(), учитывая токенизатор, максимальную длину последовательности и словарь всех описаний и фотографий, преобразует данные в пары ввода-вывода данных для обучения модели.\n",
    "\n",
    "В модели есть два входных массива: один для признаков фотографии и один для закодированного текста. Существует один вывод для модели, который представляет собой закодированное следующее слово в текстовой последовательности.\n",
    "\n",
    "Входной текст кодируется в виде целых чисел, которые будут передаваться на слой встраивания слов. Признаки изображения будут передаваться непосредственно в другую часть модели. Модель выдаст прогноз, который будет представлять собой распределение вероятностей по всем словам в словаре.\n",
    "\n",
    "Таким образом, выходные данные будут представлять собой однократно закодированную версию каждого слова, представляющую идеализированное распределение вероятностей со значениями 0 во всех позициях слов, кроме фактической позиции слова, которая имеет значение 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def image_names_set(data):\n",
    "    vals = set()\n",
    "\n",
    "    for idx in data.index:\n",
    "        vals.add(data.iat[idx, 0][:-4])\n",
    "\n",
    "    return vals\n",
    "\n",
    "def load_image_features(filename, data):\n",
    "    all_features = pickle.load(open(filename, 'rb'))\n",
    "    features = {k: all_features[k] for k in data}\n",
    "\n",
    "    return features\n",
    "\n",
    "def create_tokenizer(data):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(data)\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "def max_length(data):\n",
    "    return max(len(d.split()) for d in data)\n",
    "\n",
    "def create_sequences(tokenizer, max_length, data, images, vocab_size):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "\n",
    "    for idx in data.index:\n",
    "        seq = tokenizer.texts_to_sequences([data.iat[idx, 2]])[0]\n",
    "\n",
    "        for i in range(1, len(seq)):\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "\n",
    "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\n",
    "            X1.append(images[data.iat[idx, 0][:-4]][0])\n",
    "            X2.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "\n",
    "    return array(X1), array(X2), array(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Построение модели\n",
    "\n",
    "Мы опишем модель в трёх частях:\n",
    "\n",
    "1 – Извлечение признаков изображения. Это 16-слойная модель VGG, предварительно обученная на наборе данных ImageNet. Мы предварительно обработали изображения с помощью модели VGG (без выходного слоя) и будем использовать извлечённые признаки, предсказанные этой моделью, в качестве входных данных.\n",
    "\n",
    "2 – Обработка последовательностей. Это слой встраивания слов для обработки ввода текста, за которым следует слой рекуррентной нейронной сети с длительной кратковременной памятью (LSTM).\n",
    "\n",
    "3 – Расшифровка. (1) и (2) выводят вектор фиксированной длины. Они объединяются вместе и обрабатываются плотным слоем, чтобы сделать окончательный прогноз.\n",
    "\n",
    "Модель (1) ожидает, что входные признаки изображений будут вектором из 4096 элементов. Они обрабатываются плотным слоем для получения 256-элементного представления изображения.\n",
    "\n",
    "Модель (2) ожидает входные последовательности с заранее определённой длиной, которые подаются в слой встраивания, использующий маску для игнорирования дополненных значений. За этим следует слой LSTM с 256 единицами памяти.\n",
    "\n",
    "Обе входные модели создают вектор из 256 элементов. Кроме того, обе входные модели используют регуляризацию в виде 50% отсева (dropout). Это делается для того, чтобы уменьшить переобучение модели на текущем наборе данных, так как эта конфигурация модели обучается очень быстро.\n",
    "\n",
    "Модель (3) объединяет векторы из обеих входных моделей с помощью операции сложения. Затем этот вектор подаётся на плотный слой из 256 нейронов, а затем на конечный выходной плотный слой, который делает прогноз softmax по всему выходному словарю для следующего слова в последовательности."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def build_model(vocab_size, max_length):\n",
    "    inputs1 = Input(shape=(4096,))\n",
    "\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(256)(se2)\n",
    "\n",
    "    de1 = add([fe2, se3])\n",
    "    de2 = Dense(256, activation='relu')(de1)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(de2)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Генератор данных\n",
    "\n",
    "Генератор данных будет выдавать данные на одно изображении в каждой партии. Это будут все последовательности, сгенерированные для изображения и её набора описаний.\n",
    "\n",
    "Функция data_generator() будет генератором данных и будет принимать загруженные текстовые описания, признаки изображений, токенизатор и максимальную длину.8 ГБ оперативной памяти должно быть более чем достаточно.\n",
    "\n",
    "Вы можете видеть, что мы вызываем функцию create_sequence (), чтобы создать пакет данных для одного изображения, а не для всего набора данных. Это означает, что мы должны обновить функцию create_sequences (), чтобы удалить “итерацию по всем описаниям” для цикла.\n",
    "\n",
    "Генератор данных, предназначен для использования в вызове model.fit_generator()."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def data_generator(tokenizer, max_length, data, images, vocab_size):\n",
    "    while 1:\n",
    "        for idx in data.index:\n",
    "            image = images[data.iat[idx, 0][:-4]][0]\n",
    "            in_img, in_seq, out_word = create_sequences(tokenizer, max_length, data[idx:idx+5], image, vocab_size)\n",
    "            idx += 5\n",
    "            yield [in_img, in_seq], out_word"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Обучение"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кол-во изображений ........... 10902\n",
      "размер словаря предложений ... 26817\n",
      "длина подписи ................ 1\n"
     ]
    },
   ],
   "source": [
    "train_df = pd.read_csv(path_train, delimiter='|')\n",
    "train_features = load_image_features(path_features, image_names_set(train_df))\n",
    "print('кол-во изображений ........... %d' % len(train_features))\n",
    "\n",
    "with open (path_sentences, 'rb') as f:\n",
    "    sentences = pickle.load(f)\n",
    "tokenizer = create_tokenizer(sentences)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('размер словаря предложений ... %d' % vocab_size)\n",
    "\n",
    "max_length = max_length(train_df)\n",
    "print('длина подписи ................ %d' % max_length)\n",
    "\n",
    "train_X1, train_X2, train_y = create_sequences(tokenizer, max_length, train_df, train_features, vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}